{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0634a76-70ba-4ae1-8adc-07a1ecbb9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from he_svm import preprocess_a_sample, he_svm, preprocess_a_sample_encrypted\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f8fa5e-56d4-4629-9cfe-b7a02e286018",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_csvs = ['data/TriaxalBearings/Healthy bearing data/Healthy with pulley.csv']\n",
    "                # '../data/TriaxalBearings/Healthy bearing data/healthy without pulley.csv']\n",
    "\n",
    "LEN_SAMPLES = 500\n",
    "\n",
    "train_samples = []\n",
    "for f in healthy_csvs:\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.iloc[:, 1:]\n",
    "    dfs = df.groupby(np.arange(len(df))//LEN_SAMPLES)\n",
    "    [train_samples.append(t[1]) for t in list(dfs)[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18079997-dd9e-4eaf-9da2-dfeefe9e7111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5caab594-1fc5-4562-a73b-f5cb7ede0b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb90b6-e9f3-4c73-b45c-815eff45bf6c",
   "metadata": {},
   "source": [
    "# Train a SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d039fb-a2f5-48bc-908f-8c96c5bee47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_a_sample(df, windows):\n",
    "    final_sample = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        signal = df.loc[:, column]\n",
    "        \n",
    "        signal_fft = np.abs(np.fft.rfft(signal))**2\n",
    "        len_windows = int(len(signal_fft) / windows) - 1\n",
    "        \n",
    "        for i in range(windows):\n",
    "            if i == windows-1:\n",
    "                final_sample.append(np.mean(signal_fft[i*len_windows:]))\n",
    "            else:\n",
    "                final_sample.append(np.mean(signal_fft[i*len_windows:(i+1)*len_windows]))\n",
    "                \n",
    "    return np.array(final_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c7be470-200e-4611-b2a0-2c72799eeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e76b634-33a0-4c83-89ad-26dabe40e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_samples_nominal = np.array([preprocess_a_sample(sample, windows) for sample in train_samples])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(preprocessed_samples_nominal)\n",
    "\n",
    "n = int(len(preprocessed_samples_nominal) * 0.8)\n",
    "preprocessed_samples_train = preprocessed_samples_nominal[:n]\n",
    "preprocessed_samples_test = preprocessed_samples_nominal[n:]\n",
    "\n",
    "svm = OneClassSVM(nu=0.05, kernel='poly', gamma='scale', degree=2)\n",
    "svm.fit(preprocessed_samples_train)\n",
    "svm.gamma_value = 1 / ((windows*3) * preprocessed_samples_train.var())  # to put gamma value in svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4adba-b1f6-42b6-986a-4ff937c3030f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test\n",
    "## Test on nominal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3058e38-6f4d-4a89-87b4-d85e5edc3de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "Training samples: 189\n",
      "Found nominal: 179\n",
      "Found anomalous: 10\n",
      "Accuracy nominal training: 0.9470899470899471\n",
      "Test samples (nominal): 48\n",
      "Found nominal: 45\n",
      "Found anomalous: 3\n",
      "Accuracy nominal testing: 0.9375\n"
     ]
    }
   ],
   "source": [
    "x_predicted = svm.predict(preprocessed_samples_train)\n",
    "print(f\"###############\")\n",
    "print(f\"Training samples: {len(x_predicted)}\")\n",
    "print(f\"Found nominal: {len([x for x in x_predicted if x == 1])}\")\n",
    "print(f\"Found anomalous: {len([x for x in x_predicted if x == -1])}\")\n",
    "print(f\"Accuracy nominal training: {len([x for x in x_predicted if x == 1]) / len(x_predicted)}\")\n",
    "\n",
    "x_predicted = svm.predict(preprocessed_samples_test)\n",
    "print(f\"Test samples (nominal): {len(x_predicted)}\")\n",
    "print(f\"Found nominal: {len([x for x in x_predicted if x == 1])}\")\n",
    "print(f\"Found anomalous: {len([x for x in x_predicted if x == -1])}\")\n",
    "print(f\"Accuracy nominal testing: {len([x for x in x_predicted if x == 1]) / len(x_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19183b94-d552-4d77-ab60-df6d0bb9a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max distance: 1.0878100689276433\n",
      "Min distance: -0.8507441308006687\n"
     ]
    }
   ],
   "source": [
    "print(f'Max distance: {max(svm.decision_function(preprocessed_samples_train))}')\n",
    "print(f'Min distance: {min(svm.decision_function(preprocessed_samples_train))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a0303-0f6e-443b-aed2-6b9a76b1e25a",
   "metadata": {},
   "source": [
    "# Test on anomalous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450c0bd1-37b2-4860-b086-f52315aa34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory\n",
    "dir = 'data/TriaxalBearings/'\n",
    "\n",
    "# Get the list of files in the directory and its subdirectories\n",
    "files = []\n",
    "for f in glob.glob(dir + '**/*.csv', recursive=True):\n",
    "    if 'Healthy' not in f:\n",
    "        files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fad524-c112-4736-bb39-0221faf019e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/TriaxalBearings/0.7mm-bearing-faults/0.7inner-100watt-67V2Iv.csv\n",
      "0.7inner-100watt-67V2Iv\n",
      "Test samples (anomalous): 286\n",
      "Found nominal: 285\n",
      "Found anomalous: 1\n",
      "Accuracy: 0.35%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.7mm-bearing-faults/0.7inner-200watt-jolm8U.csv\n",
      "0.7inner-200watt-jolm8U\n",
      "Test samples (anomalous): 250\n",
      "Found nominal: 248\n",
      "Found anomalous: 2\n",
      "Accuracy: 0.8%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.7mm-bearing-faults/0.7inner-300watt-Zo8w7U.csv\n",
      "0.7inner-300watt-Zo8w7U\n",
      "Test samples (anomalous): 227\n",
      "Found nominal: 227\n",
      "Found anomalous: 0\n",
      "Accuracy: 0.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.7mm-bearing-faults/0.7outer-100watt-lB5LIS.csv\n",
      "0.7outer-100watt-lB5LIS\n",
      "Test samples (anomalous): 260\n",
      "Found nominal: 15\n",
      "Found anomalous: 245\n",
      "Accuracy: 94.23%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.7mm-bearing-faults/0.7outer-200watt-0Pp0qm.csv\n",
      "0.7outer-200watt-0Pp0qm\n",
      "Test samples (anomalous): 260\n",
      "Found nominal: 127\n",
      "Found anomalous: 133\n",
      "Accuracy: 51.15%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.7mm-bearing-faults/0.7outer-300watt-PzsIeS.csv\n",
      "0.7outer-300watt-PzsIeS\n",
      "Test samples (anomalous): 132\n",
      "Found nominal: 48\n",
      "Found anomalous: 84\n",
      "Accuracy: 63.64%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.9mm-bearing-faults/0.9inner-100watt.csv\n",
      "0.9inner-100watt\n",
      "Test samples (anomalous): 304\n",
      "Found nominal: 0\n",
      "Found anomalous: 304\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.9mm-bearing-faults/0.9inner-200watt.csv\n",
      "0.9inner-200watt\n",
      "Test samples (anomalous): 274\n",
      "Found nominal: 0\n",
      "Found anomalous: 274\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.9mm-bearing-faults/0.9inner-300watt.csv\n",
      "0.9inner-300watt\n",
      "Test samples (anomalous): 264\n",
      "Found nominal: 0\n",
      "Found anomalous: 264\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.9mm-bearing-faults/0.9outer-100watt.csv\n",
      "0.9outer-100watt\n",
      "Test samples (anomalous): 281\n",
      "Found nominal: 0\n",
      "Found anomalous: 281\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.9mm-bearing-faults/0.9outer-200watt.csv\n",
      "0.9outer-200watt\n",
      "Test samples (anomalous): 281\n",
      "Found nominal: 0\n",
      "Found anomalous: 281\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/0.9mm-bearing-faults/0.9outer-300watt.csv\n",
      "0.9outer-300watt\n",
      "Test samples (anomalous): 245\n",
      "Found nominal: 0\n",
      "Found anomalous: 245\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.1mm-bearing-faults/1.1inner-100watt.csv\n",
      "1.1inner-100watt\n",
      "Test samples (anomalous): 272\n",
      "Found nominal: 0\n",
      "Found anomalous: 272\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.1mm-bearing-faults/1.1inner-200watt.csv\n",
      "1.1inner-200watt\n",
      "Test samples (anomalous): 274\n",
      "Found nominal: 0\n",
      "Found anomalous: 274\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.1mm-bearing-faults/1.1inner-300watt.csv\n",
      "1.1inner-300watt\n",
      "Test samples (anomalous): 294\n",
      "Found nominal: 0\n",
      "Found anomalous: 294\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.1mm-bearing-faults/1.1outer-100watt.csv\n",
      "1.1outer-100watt\n",
      "Test samples (anomalous): 271\n",
      "Found nominal: 0\n",
      "Found anomalous: 271\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.1mm-bearing-faults/1.1outer-200watt.csv\n",
      "1.1outer-200watt\n",
      "Test samples (anomalous): 303\n",
      "Found nominal: 2\n",
      "Found anomalous: 301\n",
      "Accuracy: 99.34%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.1mm-bearing-faults/1.1outer-300watt.csv\n",
      "1.1outer-300watt\n",
      "Test samples (anomalous): 278\n",
      "Found nominal: 0\n",
      "Found anomalous: 278\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.3mm-bearing-faults/1.3inner-100watt.csv\n",
      "1.3inner-100watt\n",
      "Test samples (anomalous): 286\n",
      "Found nominal: 0\n",
      "Found anomalous: 286\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.3mm-bearing-faults/1.3inner-200watt.csv\n",
      "1.3inner-200watt\n",
      "Test samples (anomalous): 266\n",
      "Found nominal: 0\n",
      "Found anomalous: 266\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.3mm-bearing-faults/1.3inner-300watt.csv\n",
      "1.3inner-300watt\n",
      "Test samples (anomalous): 255\n",
      "Found nominal: 0\n",
      "Found anomalous: 255\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.3mm-bearing-faults/1.3outer-100watt.csv\n",
      "1.3outer-100watt\n",
      "Test samples (anomalous): 265\n",
      "Found nominal: 0\n",
      "Found anomalous: 265\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.3mm-bearing-faults/1.3outer-200watt.csv\n",
      "1.3outer-200watt\n",
      "Test samples (anomalous): 278\n",
      "Found nominal: 0\n",
      "Found anomalous: 278\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.3mm-bearing-faults/1.3outer-300watt.csv\n",
      "1.3outer-300watt\n",
      "Test samples (anomalous): 255\n",
      "Found nominal: 9\n",
      "Found anomalous: 246\n",
      "Accuracy: 96.47%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.5mm-bearing-faults/1.5inner-100watt.csv\n",
      "1.5inner-100watt\n",
      "Test samples (anomalous): 262\n",
      "Found nominal: 0\n",
      "Found anomalous: 262\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.5mm-bearing-faults/1.5inner-200watt.csv\n",
      "1.5inner-200watt\n",
      "Test samples (anomalous): 291\n",
      "Found nominal: 0\n",
      "Found anomalous: 291\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.5mm-bearing-faults/1.5inner-300watt.csv\n",
      "1.5inner-300watt\n",
      "Test samples (anomalous): 267\n",
      "Found nominal: 0\n",
      "Found anomalous: 267\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.5mm-bearing-faults/1.5outer-100watt.csv\n",
      "1.5outer-100watt\n",
      "Test samples (anomalous): 263\n",
      "Found nominal: 1\n",
      "Found anomalous: 262\n",
      "Accuracy: 99.62%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.5mm-bearing-faults/1.5outer-200watt.csv\n",
      "1.5outer-200watt\n",
      "Test samples (anomalous): 251\n",
      "Found nominal: 0\n",
      "Found anomalous: 251\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.5mm-bearing-faults/1.5outer-300watt.csv\n",
      "1.5outer-300watt\n",
      "Test samples (anomalous): 270\n",
      "Found nominal: 0\n",
      "Found anomalous: 270\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.7mm-bearing-faults/1.7inner-100watt.csv\n",
      "1.7inner-100watt\n",
      "Test samples (anomalous): 276\n",
      "Found nominal: 0\n",
      "Found anomalous: 276\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.7mm-bearing-faults/1.7inner-200watt.csv\n",
      "1.7inner-200watt\n",
      "Test samples (anomalous): 275\n",
      "Found nominal: 0\n",
      "Found anomalous: 275\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.7mm-bearing-faults/1.7inner-300watt.csv\n",
      "1.7inner-300watt\n",
      "Test samples (anomalous): 257\n",
      "Found nominal: 0\n",
      "Found anomalous: 257\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.7mm-bearing-faults/1.7outer-100watt.csv\n",
      "1.7outer-100watt\n",
      "Test samples (anomalous): 272\n",
      "Found nominal: 0\n",
      "Found anomalous: 272\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.7mm-bearing-faults/1.7outer-200watt.csv\n",
      "1.7outer-200watt\n",
      "Test samples (anomalous): 261\n",
      "Found nominal: 0\n",
      "Found anomalous: 261\n",
      "Accuracy: 100.0%\n",
      "###############\n",
      "File: data/TriaxalBearings/1.7mm-bearing-faults/1.7outer-300watt.csv\n",
      "1.7outer-300watt\n",
      "Test samples (anomalous): 274\n",
      "Found nominal: 0\n",
      "Found anomalous: 274\n",
      "Accuracy: 100.0%\n",
      "###############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Sides</th>\n",
       "      <th colspan=\"3\" halign=\"left\">inner</th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Powers</th>\n",
       "      <th>100w</th>\n",
       "      <th>200w</th>\n",
       "      <th>300w</th>\n",
       "      <th>100w</th>\n",
       "      <th>200w</th>\n",
       "      <th>300w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.23</td>\n",
       "      <td>51.15</td>\n",
       "      <td>63.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.34</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.62</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sides   inner                outer              \n",
       "Powers   100w   200w   300w   100w   200w   300w\n",
       "0.7      0.35    0.8    0.0  94.23  51.15  63.64\n",
       "0.9     100.0  100.0  100.0  100.0  100.0  100.0\n",
       "1.1     100.0  100.0  100.0  100.0  99.34  100.0\n",
       "1.3     100.0  100.0  100.0  100.0  100.0  96.47\n",
       "1.5     100.0  100.0  100.0  99.62  100.0  100.0\n",
       "1.7     100.0  100.0  100.0  100.0  100.0  100.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sides = ['inner', 'outer']\n",
    "powers = ['100w', '200w', '300w']\n",
    "\n",
    "multi_index = pd.MultiIndex.from_product([sides, powers], names=['Sides', 'Powers'])\n",
    "table_accuracy = pd.DataFrame(columns = multi_index) \n",
    "\n",
    "for f in sorted(files):\n",
    "    print(f\"File: {f}\")\n",
    "    short_file = f.split(\"/\")[-1][:-4]\n",
    "    print(short_file)\n",
    "    \n",
    "    side = short_file[3:8]\n",
    "    power = short_file[9:13]\n",
    "    depth = short_file[:3]\n",
    "        \n",
    "    df = pd.read_csv(f)\n",
    "    df = df.iloc[:, 1:]\n",
    "    dfs = df.groupby(np.arange(len(df))//LEN_SAMPLES)\n",
    "    anomalous_samples = [t[1] for t in list(dfs)[:-1]]\n",
    "    anomaly_samples = np.array([preprocess_a_sample(df, windows) for df in anomalous_samples])\n",
    "\n",
    "    x_predicted = svm.predict(anomaly_samples)\n",
    "    \n",
    "    n_nom = len([x for x in x_predicted if x == 1])\n",
    "    n_ano = len([x for x in x_predicted if x == -1])\n",
    "    accuracy = round((n_ano / len(x_predicted)) * 100, 2)\n",
    "    table_accuracy.loc[depth, (side, power)] = accuracy\n",
    "    \n",
    "    print(f\"Test samples (anomalous): {len(x_predicted)}\")\n",
    "    print(f\"Found nominal: {n_nom}\")\n",
    "    print(f\"Found anomalous: {n_ano}\")\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "    print(f\"###############\")\n",
    "\n",
    "display(table_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a611c-12bd-47ee-8918-a147e72b87e4",
   "metadata": {},
   "source": [
    "# Test on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33757dbe-c548-43ff-bff0-3d47a1af2cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: 1.7outer-200watt\n",
      "     ID  Expected  Predicted (enc)       % Error  Correct?  Time enc (s)\n",
      "0  None -1.814035        -1.814035  3.355487e-08      True      8.473139\n",
      "Sensor: 1.7outer-100watt\n",
      "     ID  Expected  Predicted (enc)       % Error  Correct?  Time enc (s)\n",
      "0  None -1.824547        -1.824547  3.359056e-08      True      8.492496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/falcetta/EAD_Submission/EVAD.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225a6575734c6563636f227d/home/falcetta/EAD_Submission/EVAD.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m enc_time \u001b[39m=\u001b[39m CodeTimer(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225a6575734c6563636f227d/home/falcetta/EAD_Submission/EVAD.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mwith\u001b[39;00m enc_time:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225a6575734c6563636f227d/home/falcetta/EAD_Submission/EVAD.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     x_enc_preprocessed \u001b[39m=\u001b[39m preprocess_a_sample_encrypted(sample, context, windows, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225a6575734c6563636f227d/home/falcetta/EAD_Submission/EVAD.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     x_enc_predicted \u001b[39m=\u001b[39m he_svm(x_enc_preprocessed, svm, windows)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225a6575734c6563636f227d/home/falcetta/EAD_Submission/EVAD.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     x_predicted \u001b[39m=\u001b[39m x_enc_predicted[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdecrypt()[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/EAD_Submission/he_svm.py:97\u001b[0m, in \u001b[0;36mpreprocess_a_sample_encrypted\u001b[0;34m(sample, context, windows, scaler)\u001b[0m\n\u001b[1;32m     94\u001b[0m     stack_matrices\u001b[39m.\u001b[39mappend(W \u001b[39m@\u001b[39m tuple_of_stack_matrices[i])\n\u001b[1;32m     96\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n_axes):\n\u001b[0;32m---> 97\u001b[0m     encrypted_vectors[i] \u001b[39m=\u001b[39m ((encrypted_vectors[i] \u001b[39m@\u001b[39;49m W_fourier) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m@\u001b[39m stack_matrices[i]\n\u001b[1;32m     99\u001b[0m final_encrypted_sample \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(encrypted_vectors)\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m scaler:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/evad--jNsjQLW-py3.8/lib/python3.8/site-packages/tenseal/tensors/ckksvector.py:169\u001b[0m, in \u001b[0;36mCKKSVector.__matmul__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__matmul__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCKKSVector\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmm(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/evad--jNsjQLW-py3.8/lib/python3.8/site-packages/tenseal/tensors/ckksvector.py:155\u001b[0m, in \u001b[0;36mCKKSVector.mm\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmm\u001b[39m(\u001b[39mself\u001b[39m, other) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCKKSVector\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    154\u001b[0m     other \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mm(other)\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mmm(other))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from linetimer import CodeTimer\n",
    "import tenseal as ts\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "poly_modulus_degree=2**14\n",
    "coeff_mod_bit_sizes=[60] + [50]*6 + [60]\n",
    "\n",
    "# Setup TenSEAL context\n",
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=poly_modulus_degree,\n",
    "            coeff_mod_bit_sizes=coeff_mod_bit_sizes\n",
    "          )\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**50\n",
    "\n",
    "errors = {}\n",
    "\n",
    "for f in files:\n",
    "    error_df = pd.DataFrame(columns=['ID', 'Expected', 'Predicted (enc)', '% Error', 'Correct?', 'Time enc (s)'])\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.iloc[:, 1:]\n",
    "    dfs = df.groupby(np.arange(len(df))//LEN_SAMPLES)\n",
    "    anomalous_samples = [t[1] for t in list(dfs)[:-1]]\n",
    "    \n",
    "    for sample in anomalous_samples[:]:\n",
    "        anomaly_sample = preprocess_a_sample(sample, windows).reshape(1, -1)\n",
    "        \n",
    "        x_expected = svm.decision_function(anomaly_sample)[0]\n",
    "\n",
    "        enc_time = CodeTimer(silent=True, unit='s')\n",
    "        with enc_time:\n",
    "            x_enc_preprocessed = preprocess_a_sample_encrypted(sample, context, windows, None)\n",
    "            x_enc_predicted = he_svm(x_enc_preprocessed, svm, windows)\n",
    "            x_predicted = x_enc_predicted[0].decrypt()[0]\n",
    "\n",
    "        error_df.loc[len(error_df)] = [sample.index.name, x_expected, x_predicted, \n",
    "                                       (x_expected-x_predicted)/x_expected, \n",
    "                                       np.sign(x_expected) == np.sign(x_predicted),\n",
    "                                       enc_time.took]\n",
    "\n",
    "    f = f.split(\"/\")[-1][:-4]\n",
    "    errors[f] = error_df\n",
    "    error_df.to_csv(f\"results/TriaxalBearings/Errors_{f}.csv\")\n",
    "\n",
    "    print(f\"Sensor: {f}\")\n",
    "    print(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204fe71-a8a5-4690-b2a8-3063767da274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evad--jNsjQLW-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
